{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tg-oWANXLYR2"
      },
      "outputs": [],
      "source": [
        "# Import Necessary Libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')  # Suppress all warnings"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#download necessary NLTK data\n",
        "nltk.download('punkt_tab') #for tokenizer\n",
        "nltk.download('stopwords') #for stopwords"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xN4xYh3uXOPK",
        "outputId": "f545d1c0-4a56-40fa-e13b-12ffb5c0be25"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Example text\n",
        "text = \"Natural Language Processing is an amazing field!\""
      ],
      "metadata": {
        "id": "mk8OotYlZ-NV"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenization\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E9U6_12OaHxb",
        "outputId": "d9a4320f-7f60-4223-e1fb-bd56fb185f8b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Natural', 'Language', 'Processing', 'is', 'an', 'amazing', 'field', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "filtered_tokens = [word for word in tokens if word.lower() not in stop_words]\n",
        "# print(filtered_tokens)"
      ],
      "metadata": {
        "id": "SEIxVC6JbcO7"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Original Tokens:\", tokens)\n",
        "print(\"Filtered Tokens:\", filtered_tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "52XKu5vEcheq",
        "outputId": "d752bba8-6667-41aa-9084-443b22211d5a"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Tokens: ['Natural', 'Language', 'Processing', 'is', 'an', 'amazing', 'field', '!']\n",
            "Filtered Tokens: ['Natural', 'Language', 'Processing', 'amazing', 'field', '!']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoModelForCausalLM, AutoTokenizer"
      ],
      "metadata": {
        "id": "Lkm2eCfrhZHP"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"microsoft/DialoGPT-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "B7A_K6Zehh6d"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Chatbot interaction\n",
        "user_input = input()\n",
        "input_ids = tokenizer.encode(user_input, return_tensors=\"pt\")\n",
        "print(input_ids)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FXtkSJ0WiA-D",
        "outputId": "93e3b71c-0c3e-42d8-ca8f-a60db2f5d68c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "I want to\n",
            "tensor([[ 40, 765, 284]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_ids = model.generate(input_ids, max_length=15)\n",
        "response = tokenizer.decode(response_ids[0], skip_special_tokens=True)\n",
        "print(\"Chatbot:\", response)\n",
        "print(response_ids)\n",
        "print(tokenizer.decode(response_ids[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mXtg_USUiKYw",
        "outputId": "d1e33902-2a28-4974-9c2e-d7f890076b34"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chatbot: I want to say it was a joke?\n",
            "tensor([[   40,   765,   284,   910,   340,   373,   257,  9707,  5633, 50256]])\n",
            "I want to say it was a joke?<|endoftext|>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ObQk9MSQkB3v"
      },
      "execution_count": 22,
      "outputs": []
    }
  ]
}